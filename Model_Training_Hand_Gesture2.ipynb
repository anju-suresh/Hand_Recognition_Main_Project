{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSnvRQnJvoSh"
   },
   "source": [
    "## Creating Neural Network Model for Hand Gesture Classification \n",
    "\n",
    "Gestures for \n",
    "\n",
    "*  Play\n",
    "*   Pause\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvuUquDCb-0f",
    "outputId": "543290a3-f655-4dba-cde3-336ecf9595a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'dataset' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#Loading Dataset\n",
    "\n",
    "!git clone https://github.com/anju-suresh/dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYblOQVo9mlE"
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmKYHbi0cMMh",
    "outputId": "8b0490cc-5af0-47bc-c345-b357240f14c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 11:01:05.298444: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4jZxOX4ZVVK"
   },
   "outputs": [],
   "source": [
    "#Finding Image path\n",
    "\n",
    "imagePaths = list(paths.list_images('dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BouYeqeDcUDp"
   },
   "outputs": [],
   "source": [
    "#Retrieving Labels from Image Paths\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "  label = imagePath.split(os.path.sep)[-2]\n",
    "  image = load_img(imagePath, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "  image = img_to_array(image)\n",
    "  image = image/255\n",
    "\n",
    "  data.append(image)\n",
    "  labels.append(label)\n",
    "\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JoZQQQNcwJK",
    "outputId": "539a5c61-5e1e-4f2b-bc38-2101d164e4c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['play', 'stop'], dtype='<U4'), array([300, 300]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding Label Values\n",
    "\n",
    "np. unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJ8z-hTdwMmq"
   },
   "source": [
    "### Preprocessing the label by encoding them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hinyeohuczXq"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfqoXRZqdFrK"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51PapX4edSn5",
    "outputId": "d5c25fec-1a21-471c-bb43-b170d58e7a56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZd6F0OBdb64"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\ttest_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LjLKcoqdeXQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2IdsZWqd9X2",
    "outputId": "78b49282-d396-4d2b-e346-65fae0b02744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 11:01:13.279183: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Using ResNet for Feature Extraction\n",
    "\n",
    "feature_extractor_layer = ResNet50V2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(IMG_SIZE,IMG_SIZE,CHANNELS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMVaJh3Qd_iI"
   },
   "outputs": [],
   "source": [
    "feature_extractor_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMfLzDXdeEbp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ms8NdZXTeGJ_"
   },
   "outputs": [],
   "source": [
    "# Model building\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(feature_extractor_layer)\n",
    "model.add(layers.Flatten(name=\"flatten\"))\n",
    "model.add(layers.Dense(1024, activation='relu', name='hidden_layer'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2, activation='softmax', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qd8XVJNTeIcY",
    "outputId": "ca35e33d-33e3-4c29-b038-242cf3d87ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 1024)              102761472 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,328,322\n",
      "Trainable params: 102,763,522\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6I346dEeSQF"
   },
   "outputs": [],
   "source": [
    "#Compliling Model\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "  loss=\"categorical_crossentropy\",\n",
    "  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Qqv3LUOeUIG"
   },
   "outputs": [],
   "source": [
    "#Pre-processing Image before training Model\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "en5WcQDAeVzW",
    "outputId": "5cea85ca-fa98-4145-dfdf-dee7569a8985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 45s 3s/step - loss: 0.2297 - accuracy: 0.9271 - val_loss: 9.9341e-10 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 40s 3s/step - loss: 2.6000e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 43s 3s/step - loss: 1.6069e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 40s 3s/step - loss: 2.0163e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 41s 3s/step - loss: 6.0868e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 41s 3s/step - loss: 2.4764e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 46s 3s/step - loss: 4.0313e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 43s 3s/step - loss: 3.0249e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 42s 3s/step - loss: 7.5928e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 43s 3s/step - loss: 8.6198e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Fitting Model\n",
    "\n",
    "history = model.fit(aug.flow(trainX, trainY),\n",
    "\t                  validation_data=(testX, testY),\n",
    "\t                  epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lq3fn6oreX2-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_SeUUKZ_lT93",
    "outputId": "09332d2b-e499-44d8-bedb-2997906163aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 8s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predIdxs = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9h5G5GWjqpa",
    "outputId": "ce7ab52f-fefd-4b07-aac4-609e09c939c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4363586e-12, 1.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predIdxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VQW-tGAjq4r"
   },
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FEzyP5MjsbS",
    "outputId": "d5fb5d89-e764-4e6f-e5c5-4184c09cb837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        play       1.00      1.00      1.00        60\n",
      "        stop       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIdxs,target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL_0jZonjxQj"
   },
   "outputs": [],
   "source": [
    "model.save('model_hand_gesture.h5', save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZBHPl3ik2KC",
    "outputId": "52dcf633-321d-46ee-e179-449bdabff52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2G\tmodel_hand_gesture.h5\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
